{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alifftwa/Dataset-Daun-Jeruk-Nipis-dan-Daun-Kemangi_100_102/blob/main/Uts_Kecerdasan_Buatan_Luthfi_Rizzaludin_(100)_dan_Alif_Fatwa_Ramadhani_(102).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHIicQ0pLWip",
        "outputId": "b67d2406-55fc-4f74-fe3f-bcab8cbf9038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1m7cW_8NNuZ",
        "outputId": "b3763b6c-433a-4de3-b329-7bd94fdb17a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Colab Notebooks/Coba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d30147b6NXNc",
        "outputId": "10e06cb4-e646-4eff-b261-f77d6952591a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 107] Transport endpoint is not connected: '/content/gdrive/My Drive/Colab Notebooks/Coba'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "\n",
        "train_dir = \"/content/drive/My Drive/Colab Notebooks/Coba/train\"\n",
        "val_dir = \"/content/drive/My Drive/Colab Notebooks/Coba/test\"\n",
        "\n",
        "jeruk_train_path = train_dir +'/Daun Jeruk'\n",
        "kemangi_train_path = train_dir +'/Daun Kemangi'\n",
        "jeruk_val_path = val_dir +'/Daun Jeruk'\n",
        "kemangi_val_path = val_dir +'/Daun Kemangi'\n",
        "\n",
        "jeruk_len_train = len(os.listdir(jeruk_train_path))\n",
        "kemangi_len_train = len(os.listdir(kemangi_train_path))\n",
        "jeruk_len_val = len(os.listdir(jeruk_val_path))\n",
        "kemangi_len_val = len(os.listdir(kemangi_val_path))\n",
        "\n",
        "print(\"jumlah dataset Training : \", jeruk_len_train + jeruk_len_train)\n",
        "print(\"jumlah dataset validasi : \", jeruk_len_val + jeruk_len_val)\n",
        "print(\"\\n\\n\")\n",
        "print(\"jumlah train kelas jeruk : \", jeruk_len_train)\n",
        "print(\"jumlah train kelas kemangi : \", kemangi_len_train)\n",
        "print(\"jumlah validasi kelas jeruk : \", jeruk_len_val)\n",
        "print(\"jumlah validasi kelas kemangi : \", kemangi_len_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4cCPRdMNgnm",
        "outputId": "3ae90ff5-a3ff-4415-9f26-d1bd376fd56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumlah dataset Training :  100\n",
            "jumlah dataset validasi :  100\n",
            "\n",
            "\n",
            "\n",
            "jumlah train kelas jeruk :  50\n",
            "jumlah train kelas kemangi :  50\n",
            "jumlah validasi kelas jeruk :  50\n",
            "jumlah validasi kelas kemangi :  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "2NzaaystNmJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(50, 50),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(50, 50),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiobHM7mRZVW",
        "outputId": "433b26f5-f6a2-4138-f734-edc3e878c2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Conv2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dropout"
      ],
      "metadata": {
        "id": "JHNf_iS4SJ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(InputLayer(input_shape=[50, 50,3]))\n",
        "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.0001))"
      ],
      "metadata": {
        "id": "ziMKeaePSMW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.0001))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.0001))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "L1cOOKikSPD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDvNL9B7SR0t",
        "outputId": "dcf2c5a1-d20c-43e3-dc13-e6c88827851a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 50, 64)        1792      \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 25, 25, 64)       0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 128)       73856     \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 13, 13, 128)      0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 256)       295168    \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 7, 7, 256)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 4, 4, 256)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 256)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              263168    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,274,689\n",
            "Trainable params: 2,274,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.0001), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-kQ08IkSVJV",
        "outputId": "3411bc6f-c06b-4407-adb1-50a9ec8ec245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "EPzOaYL5SXo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks = EarlyStopping(monitor='val_loss', patience=30, verbose=1, mode='auto')        \n",
        "directory_to_save_best_model_file = '/content/drive/My Drive/Colab Notebooks/coba/coba.h5'\n",
        "best_model = ModelCheckpoint(directory_to_save_best_model_file, monitor='val_acc', verbose = 1, save_best_only = True)"
      ],
      "metadata": {
        "id": "pVWBOUF1SaAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=5,  \n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=5,  \n",
        "      \n",
        "      callbacks = [callbacks, best_model])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsE-G67DYaF0",
        "outputId": "d0711c9a-2af1-4abd-a06a-461cae3f7b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6845 - acc: 0.5000\n",
            "Epoch 1: val_acc improved from -inf to 0.50000, saving model to /content/drive/My Drive/Colab Notebooks/coba/coba.h5\n",
            "5/5 [==============================] - 56s 10s/step - loss: 0.6845 - acc: 0.5000 - val_loss: 0.6803 - val_acc: 0.5000\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6773 - acc: 0.5000\n",
            "Epoch 2: val_acc did not improve from 0.50000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6773 - acc: 0.5000 - val_loss: 0.6753 - val_acc: 0.5000\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6742 - acc: 0.5000\n",
            "Epoch 3: val_acc did not improve from 0.50000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6742 - acc: 0.5000 - val_loss: 0.6699 - val_acc: 0.5000\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6682 - acc: 0.5000\n",
            "Epoch 4: val_acc did not improve from 0.50000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6682 - acc: 0.5000 - val_loss: 0.6626 - val_acc: 0.5000\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6641 - acc: 0.5000\n",
            "Epoch 5: val_acc did not improve from 0.50000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6641 - acc: 0.5000 - val_loss: 0.6542 - val_acc: 0.5000\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6520 - acc: 0.5000\n",
            "Epoch 6: val_acc did not improve from 0.50000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6520 - acc: 0.5000 - val_loss: 0.6424 - val_acc: 0.5000\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6455 - acc: 0.5000\n",
            "Epoch 7: val_acc did not improve from 0.50000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6455 - acc: 0.5000 - val_loss: 0.6246 - val_acc: 0.5000\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6295 - acc: 0.5800\n",
            "Epoch 8: val_acc improved from 0.50000 to 0.54000, saving model to /content/drive/My Drive/Colab Notebooks/coba/coba.h5\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6295 - acc: 0.5800 - val_loss: 0.6008 - val_acc: 0.5400\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6037 - acc: 0.5600\n",
            "Epoch 9: val_acc improved from 0.54000 to 0.86000, saving model to /content/drive/My Drive/Colab Notebooks/coba/coba.h5\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6037 - acc: 0.5600 - val_loss: 0.5700 - val_acc: 0.8600\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5659 - acc: 0.6700\n",
            "Epoch 10: val_acc improved from 0.86000 to 0.97000, saving model to /content/drive/My Drive/Colab Notebooks/coba/coba.h5\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.5659 - acc: 0.6700 - val_loss: 0.5224 - val_acc: 0.9700\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5075 - acc: 0.9000\n",
            "Epoch 11: val_acc did not improve from 0.97000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.5075 - acc: 0.9000 - val_loss: 0.4462 - val_acc: 0.8000\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4275 - acc: 0.8700\n",
            "Epoch 12: val_acc did not improve from 0.97000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.4275 - acc: 0.8700 - val_loss: 0.3676 - val_acc: 0.8500\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3441 - acc: 0.9500\n",
            "Epoch 13: val_acc improved from 0.97000 to 1.00000, saving model to /content/drive/My Drive/Colab Notebooks/coba/coba.h5\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.3441 - acc: 0.9500 - val_loss: 0.2416 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2301 - acc: 0.9800\n",
            "Epoch 14: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 12s 3s/step - loss: 0.2301 - acc: 0.9800 - val_loss: 0.1404 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1349 - acc: 0.9900\n",
            "Epoch 15: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.1349 - acc: 0.9900 - val_loss: 0.1005 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0877 - acc: 0.9900\n",
            "Epoch 16: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0877 - acc: 0.9900 - val_loss: 0.0300 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1012 - acc: 0.9600\n",
            "Epoch 17: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.1012 - acc: 0.9600 - val_loss: 0.3916 - val_acc: 0.8000\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1335 - acc: 0.9400\n",
            "Epoch 18: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.1335 - acc: 0.9400 - val_loss: 0.0555 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0835 - acc: 0.9600\n",
            "Epoch 19: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0835 - acc: 0.9600 - val_loss: 0.0485 - val_acc: 0.9900\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2178 - acc: 0.9000\n",
            "Epoch 20: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.2178 - acc: 0.9000 - val_loss: 0.1427 - val_acc: 0.9300\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3991 - acc: 0.8500\n",
            "Epoch 21: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.3991 - acc: 0.8500 - val_loss: 0.7416 - val_acc: 0.6500\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2740 - acc: 0.8700\n",
            "Epoch 22: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.2740 - acc: 0.8700 - val_loss: 0.3400 - val_acc: 0.8100\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2307 - acc: 0.9100\n",
            "Epoch 23: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.2307 - acc: 0.9100 - val_loss: 0.1576 - val_acc: 0.9200\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1910 - acc: 0.9000\n",
            "Epoch 24: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.1910 - acc: 0.9000 - val_loss: 0.0245 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.9600\n",
            "Epoch 25: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.1179 - acc: 0.9600 - val_loss: 0.0217 - val_acc: 1.0000\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0491 - acc: 0.9800\n",
            "Epoch 26: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0491 - acc: 0.9800 - val_loss: 0.0807 - val_acc: 0.9800\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0651 - acc: 0.9800\n",
            "Epoch 27: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0651 - acc: 0.9800 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0547 - acc: 0.9900\n",
            "Epoch 28: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0547 - acc: 0.9900 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0338 - acc: 1.0000\n",
            "Epoch 29: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0528 - acc: 0.9800\n",
            "Epoch 30: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0528 - acc: 0.9800 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0400 - acc: 0.9900\n",
            "Epoch 31: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0400 - acc: 0.9900 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0277 - acc: 0.9900\n",
            "Epoch 32: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0277 - acc: 0.9900 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0315 - acc: 1.0000\n",
            "Epoch 33: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0189 - acc: 1.0000\n",
            "Epoch 34: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0165 - acc: 1.0000\n",
            "Epoch 35: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.9900\n",
            "Epoch 36: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0274 - acc: 0.9900 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0360 - acc: 0.9800\n",
            "Epoch 37: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0360 - acc: 0.9800 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0334 - acc: 0.9900\n",
            "Epoch 38: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0334 - acc: 0.9900 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0091 - acc: 1.0000\n",
            "Epoch 39: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0383 - acc: 0.9700\n",
            "Epoch 40: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0383 - acc: 0.9700 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0100 - acc: 1.0000\n",
            "Epoch 41: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 42: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0178 - acc: 1.0000\n",
            "Epoch 43: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 44: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9900\n",
            "Epoch 45: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0253 - acc: 0.9900 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9900\n",
            "Epoch 46: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0176 - acc: 0.9900 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0123 - acc: 1.0000\n",
            "Epoch 47: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0108 - acc: 1.0000\n",
            "Epoch 48: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9800\n",
            "Epoch 49: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.0456 - acc: 0.9800 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0213 - acc: 1.0000\n",
            "Epoch 50: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0290 - acc: 0.9800\n",
            "Epoch 51: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0290 - acc: 0.9800 - val_loss: 0.0036 - val_acc: 1.0000\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0123 - acc: 1.0000\n",
            "Epoch 52: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9900\n",
            "Epoch 53: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0178 - acc: 0.9900 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 54: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0182 - acc: 0.9900\n",
            "Epoch 55: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0182 - acc: 0.9900 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 56: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 57: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0214 - acc: 0.9900\n",
            "Epoch 58: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0214 - acc: 0.9900 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 59: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.0000\n",
            "Epoch 60: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0104 - acc: 1.0000 - val_loss: 7.8417e-04 - val_acc: 1.0000\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 61: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0023 - acc: 1.0000 - val_loss: 8.0332e-04 - val_acc: 1.0000\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 62: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0044 - acc: 1.0000 - val_loss: 7.6110e-04 - val_acc: 1.0000\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0085 - acc: 1.0000\n",
            "Epoch 63: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9900\n",
            "Epoch 64: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0145 - acc: 0.9900 - val_loss: 0.0049 - val_acc: 1.0000\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0346 - acc: 0.9900\n",
            "Epoch 65: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0346 - acc: 0.9900 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0161 - acc: 0.9900\n",
            "Epoch 66: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0161 - acc: 0.9900 - val_loss: 7.1261e-04 - val_acc: 1.0000\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 67: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0088 - acc: 1.0000\n",
            "Epoch 68: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0088 - acc: 1.0000 - val_loss: 8.7038e-04 - val_acc: 1.0000\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0162 - acc: 1.0000\n",
            "Epoch 69: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0162 - acc: 1.0000 - val_loss: 4.8580e-04 - val_acc: 1.0000\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9900\n",
            "Epoch 70: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0157 - acc: 0.9900 - val_loss: 4.6388e-04 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 71: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0070 - acc: 1.0000 - val_loss: 4.6368e-04 - val_acc: 1.0000\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9900\n",
            "Epoch 72: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0136 - acc: 0.9900 - val_loss: 4.3605e-04 - val_acc: 1.0000\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 73: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0041 - acc: 1.0000 - val_loss: 4.7249e-04 - val_acc: 1.0000\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.0000    \n",
            "Epoch 74: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 75: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0036 - acc: 1.0000 - val_loss: 3.6670e-04 - val_acc: 1.0000\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 76: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0020 - acc: 1.0000 - val_loss: 5.2091e-04 - val_acc: 1.0000\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 77: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0048 - acc: 1.0000 - val_loss: 3.4491e-04 - val_acc: 1.0000\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 78: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0013 - acc: 1.0000 - val_loss: 9.0197e-04 - val_acc: 1.0000\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9900\n",
            "Epoch 79: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0102 - acc: 0.9900 - val_loss: 9.9452e-04 - val_acc: 1.0000\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 80: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9900\n",
            "Epoch 81: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0152 - acc: 0.9900 - val_loss: 7.0205e-04 - val_acc: 1.0000\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0147 - acc: 1.0000\n",
            "Epoch 82: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0147 - acc: 1.0000 - val_loss: 8.4772e-04 - val_acc: 1.0000\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1029 - acc: 0.9500\n",
            "Epoch 83: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.1029 - acc: 0.9500 - val_loss: 0.0493 - val_acc: 0.9800\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0892 - acc: 0.9700\n",
            "Epoch 84: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0892 - acc: 0.9700 - val_loss: 0.0532 - val_acc: 0.9900\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0295 - acc: 0.9900\n",
            "Epoch 85: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0295 - acc: 0.9900 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0155 - acc: 0.9900\n",
            "Epoch 86: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0155 - acc: 0.9900 - val_loss: 0.0023 - val_acc: 1.0000\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 87: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9900\n",
            "Epoch 88: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0114 - acc: 0.9900 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 89: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0092 - acc: 1.0000 - val_loss: 7.9389e-04 - val_acc: 1.0000\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0074 - acc: 1.0000\n",
            "Epoch 90: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0136 - acc: 1.0000\n",
            "Epoch 91: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0136 - acc: 1.0000 - val_loss: 3.6592e-04 - val_acc: 1.0000\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9900\n",
            "Epoch 92: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.0108 - acc: 0.9900 - val_loss: 5.3255e-04 - val_acc: 1.0000\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 93: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0013 - acc: 1.0000 - val_loss: 3.4287e-04 - val_acc: 1.0000\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 94: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0018 - acc: 1.0000 - val_loss: 9.1307e-04 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 95: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.8627e-04 - val_acc: 1.0000\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 96: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.5743e-04 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 97: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.9194e-04 - val_acc: 1.0000\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 98: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.0019 - acc: 1.0000 - val_loss: 3.4002e-04 - val_acc: 1.0000\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 99: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.4680e-04 - val_acc: 1.0000\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - ETA: 0s - loss: 9.4095e-04 - acc: 1.0000\n",
            "Epoch 100: val_acc did not improve from 1.00000\n",
            "5/5 [==============================] - 9s 2s/step - loss: 9.4095e-04 - acc: 1.0000 - val_loss: 2.4002e-04 - val_acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "ej06dzZoZJob",
        "outputId": "cdd15b1b-e24b-4ec6-c0a9-8cdce8cdb21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import some of library that we need to look the confusion matrix, recall, f1_score, and accuracy score to look how much your model is well\n",
        "import numpy as np \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
        "from sklearn import metrics\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')"
      ],
      "metadata": {
        "id": "j-AM8nzsc_-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_metrics(y_true, y_pred):\n",
        "    accuracy=accuracy_score(y_true, y_pred)\n",
        "    precision=precision_score(y_true, y_pred,average='weighted')\n",
        "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1Score))\n",
        "    cm=confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1Score\n",
        "\n",
        "height=50; width=50\n",
        "batch_size=20\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "TESTING_DIR = '/content/drive/My Drive/Colab Notebooks/Coba/test'\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(TESTING_DIR,\n",
        "                                                  batch_size=batch_size,                                                             \n",
        "                                                  target_size=(height, width),\n",
        "                                                  class_mode= None,\n",
        "                                                  shuffle=False\n",
        "                                                  )\n",
        "\n",
        "predictions = model.predict_generator(generator=test_generator)\n",
        "yPredictions = predictions > 0.5\n",
        "true_classes = test_generator.classes\n",
        "class_names = test_generator.class_indices\n",
        "Cmatrix_test = confusion_matrix(true_classes, yPredictions)\n",
        "\n",
        "testAcc,testPrec, testFScore = my_metrics(true_classes, yPredictions)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "ax= plt.subplot()\n",
        "data = np.asarray(Cmatrix_test).reshape(3,3)\n",
        "sns.heatmap(data,annot=True, fmt='',ax=ax, cmap=plt.cm.Reds)\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels') \n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(class_names)   \n",
        "ax.yaxis.set_ticklabels(class_names)\n",
        "plt.title('Confusion Matrix Test',fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Aw0AzgLVdDIh",
        "outputId": "d3bbad3b-3771-4e84-e8ca-60208f65c6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  : 1.0\n",
            "Precision : 1.0\n",
            "f1Score : 1.0\n",
            "[[50  0]\n",
            " [ 0 50]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ec27fe0d90ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCmatrix_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4 into shape (3,3)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(true_classes, yPredictions, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUxAJvYLfA2q",
        "outputId": "f3d7a747-3470-4667-dbfb-7e6850645170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Daun Jeruk       1.00      1.00      1.00        50\n",
            "Daun Kemangi       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZogTZD2vfDzh",
        "outputId": "220b442a-85df-4647-8e9f-bf71bcff72e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "model_path = '/content/drive/My Drive/Colab Notebooks/Coba/coba.h5''\n",
        "model = load_model(model_path)\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  \n",
        "  path= fn\n",
        "  img=load_img(path, target_size=(100,100))\n",
        "  \n",
        "  x=img_to_array(img)\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=100)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if classes[0]>0:\n",
        "    print(fn + \" is a jeruk\")\n",
        "    \n",
        "  else:\n",
        "    print(fn + \" is a belimbing\")\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "MhTE5lZIfG9h",
        "outputId": "e3e2c995-0238-49c3-eb95-70734b33547c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-8feeb8bacb37>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    model_path = '/content/drive/My Drive/Colab Notebooks/Coba/coba.h5''\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ]
    }
  ]
}